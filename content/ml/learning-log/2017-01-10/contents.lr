pub_date: 2017-01-10
---
body:

I'm working my way [cs231n](http://cs231n.github.io/), Stanford's class on convolutional neural networks. The first assignment sets the stage by having you implement a k-nearest neighbor classifier by hand. 

This is a nice warm-up as it gets you setup with the framework for image classification: train on a series of labeled images, and then predict the class of a new set of test images. 

<a href="http://cs231n.github.io/assignments2016/assignment1/">
<img src="image_classification.png" width=483>
</a>

## Reviewing vectorization

The first thing that was useful about this was simply implementing KNN by hand, first without any help from numpy's vectorizing methods, then help along one dimension, and finally figuring out how to do it without any loops at all. I spent some time reviewing [universal functions](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) and [broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html), which come in handy when re-implementing the distance matrix calculation. 

** MORE HERE **

## Why KNN stinks at image classifcation

It's useful to see that applying a nearest neighbor approach to image classification is not effective, and it makes sense: if you are doing a pixel-wise distance comparison between two images, it will be terribly sensitive to any translation of image features; imagine the exact same image having a distance of zero to itself, but then a large distance to a version of itself shifted over by a few pixels.

This motivates the need for the translation-invariant nature of features learned by convolutional layers.

** more about where to follow along my solutions **
---
summary: Practice vectorizing numpy operations, and why KNN stinks at image classification
---
_discoverable: no
